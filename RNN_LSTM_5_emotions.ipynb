{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN-LSTM-5 emotions",
      "provenance": [],
      "mount_file_id": "1Ej4TUjKzJxpQYEA25_nVyQX0DC1Jujz0",
      "authorship_tag": "ABX9TyNCYFLmxxYtpHo8l869gnmB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/varshareddykumbham/Speech-Emotion-Recognition-using-RNN-LSTM/blob/main/RNN_LSTM_5_emotions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98-5wYA-jW_K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 700
        },
        "outputId": "e2ef4e02-5e8b-4afe-92d1-1a4827ca0fb7"
      },
      "source": [
        "pip install tensorflow==1.14"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.14\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/f0/96fb2e0412ae9692dbf400e5b04432885f677ad6241c088ccc5fe7724d69/tensorflow-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (109.2MB)\n",
            "\u001b[K     |████████████████████████████████| 109.2MB 48kB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.30.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.3.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.1.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.18.5)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 37.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.8.1)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 39.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.34.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.9.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.2.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.0.8)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.12.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.14) (47.3.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.2.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14) (2.10.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (1.6.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.1.0)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, tensorflow\n",
            "  Found existing installation: tensorflow-estimator 2.2.0\n",
            "    Uninstalling tensorflow-estimator-2.2.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.2.0\n",
            "  Found existing installation: tensorboard 2.2.2\n",
            "    Uninstalling tensorboard-2.2.2:\n",
            "      Successfully uninstalled tensorboard-2.2.2\n",
            "  Found existing installation: tensorflow 2.2.0\n",
            "    Uninstalling tensorflow-2.2.0:\n",
            "      Successfully uninstalled tensorflow-2.2.0\n",
            "Successfully installed tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMF6-vYJjdjc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "5e74f8df-0960-4fe8-dc9a-73a8bca0cf87"
      },
      "source": [
        "!pip install soundfile"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting soundfile\n",
            "  Downloading https://files.pythonhosted.org/packages/eb/f2/3cbbbf3b96fb9fa91582c438b574cff3f45b29c772f94c400e2c99ef5db9/SoundFile-0.10.3.post1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.6/dist-packages (from soundfile) (1.14.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.0->soundfile) (2.20)\n",
            "Installing collected packages: soundfile\n",
            "Successfully installed soundfile-0.10.3.post1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCwWTCq7kMri",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "793cb668-b56f-47cf-e82c-253fb4300cf8"
      },
      "source": [
        "%cd /content/drive/My Drive/Emotion_Recognition_Data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Emotion_Recognition_Data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSqVX9-xoD44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "a0dec86f-8a94-47b6-c925-5c16791dca74"
      },
      "source": [
        "from deep_emotion_recognition import DeepEmotionRecognizer\n",
        "deeprec = DeepEmotionRecognizer(emotions=['angry', 'sad', 'neutral', 'ps', 'happy'], n_rnn_layers=2, n_dense_layers=2, rnn_units=128, dense_units=128)\n",
        "deeprec.train()\n",
        "print(deeprec.test_score())\n",
        "prediction = deeprec.predict('data/validation/Actor_10/03-02-05-02-02-02-10_angry.wav')\n",
        "print(f\"Prediction: {prediction}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[TESS&RAVDESS] There are 808 training audio files for category:angry\n",
            "[TESS&RAVDESS] There are 147 testing audio files for category:angry\n",
            "[TESS&RAVDESS] There are 812 training audio files for category:sad\n",
            "[TESS&RAVDESS] There are 146 testing audio files for category:sad\n",
            "[TESS&RAVDESS] There are 585 training audio files for category:neutral\n",
            "[TESS&RAVDESS] There are 93 testing audio files for category:neutral\n",
            "[TESS&RAVDESS] There are 513 training audio files for category:ps\n",
            "[TESS&RAVDESS] There are 77 testing audio files for category:ps\n",
            "[TESS&RAVDESS] There are 805 training audio files for category:happy\n",
            "[TESS&RAVDESS] There are 147 testing audio files for category:happy\n",
            "[+] Writed TESS & RAVDESS DB CSV File\n",
            "[EMO-DB] Total files to write: 340\n",
            "[EMO-DB] Training samples: 272\n",
            "[EMO-DB] Testing samples: 67\n",
            "[+] Writed EMO-DB CSV File\n",
            "[Custom Dataset] There are 49 training audio files for category:neutral\n",
            "[Custom Dataset] There are 33 testing audio files for category:neutral\n",
            "[Custom Dataset] There are 33 training audio files for category:ps\n",
            "[Custom Dataset] There are 33 testing audio files for category:ps\n",
            "[Custom Dataset] There are 48 training audio files for category:happy\n",
            "[Custom Dataset] There are 23 testing audio files for category:happy\n",
            "[+] Writed Custom DB CSV File\n",
            "[+] Data loaded\n",
            "[+] Model created\n",
            "[*] Model weights loaded\n",
            "0.8846153846153846\n",
            "Prediction: angry\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0ZShAbOtyaX"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "stderr = sys.stderr\n",
        "sys.stderr = open(os.devnull, 'w')\n",
        "import keras\n",
        "sys.stderr = stderr\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "import tensorflow as tf\n",
        "\n",
        "config = tf.ConfigProto(intra_op_parallelism_threads=5,\n",
        "                        inter_op_parallelism_threads=5, \n",
        "                        allow_soft_placement=True,\n",
        "                        device_count = {'CPU' : 1,\n",
        "                                        'GPU' : 0}\n",
        "                       )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypt-7Eont3FD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "97fcd1a5-8c1c-4155-d5f9-f31c3f800741"
      },
      "source": [
        "from keras.layers import LSTM, GRU, Dense, Activation, LeakyReLU, Dropout\n",
        "from keras.layers import Conv1D, MaxPool1D, GlobalAveragePooling1D\n",
        "from keras.models import Sequential\n",
        "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "from sklearn.metrics import accuracy_score, mean_absolute_error, confusion_matrix,classification_report\n",
        "import numpy as np\n",
        "import seaborn as sns \n",
        "\n",
        "from data_extractor import load_data\n",
        "from create_csv import write_custom_csv, write_emodb_csv, write_tess_ravdess_csv\n",
        "from emotion_recognition import EmotionRecognizer\n",
        "from utils import get_first_letters, AVAILABLE_EMOTIONS, extract_feature, get_dropout_str\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_IcsKtpoEZN"
      },
      "source": [
        "class DeepEmotionRecognizer(EmotionRecognizer):\n",
        "    \"\"\"\n",
        "    The Deep Learning version of the Emotion Recognizer.\n",
        "    This class uses RNN (LSTM, GRU, etc.) and Dense layers.\n",
        "    #TODO add CNNs\n",
        "    \"\"\"\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(None, **kwargs)\n",
        "\n",
        "        self.n_rnn_layers = kwargs.get(\"n_rnn_layers\", 2)\n",
        "        self.n_dense_layers = kwargs.get(\"n_dense_layers\", 2)\n",
        "        self.rnn_units = kwargs.get(\"rnn_units\", 128)\n",
        "        self.dense_units = kwargs.get(\"dense_units\", 128)\n",
        "        self.cell = kwargs.get(\"cell\", LSTM)\n",
        "\n",
        "        self.dropout = kwargs.get(\"dropout\", 0.3)\n",
        "        self.dropout = self.dropout if isinstance(self.dropout, list) else [self.dropout] * ( self.n_rnn_layers + self.n_dense_layers )\n",
        "        self.output_dim = len(self.emotions)\n",
        "\n",
        "        self.optimizer = kwargs.get(\"optimizer\", \"adam\")\n",
        "        self.loss = kwargs.get(\"loss\", \"categorical_crossentropy\")\n",
        "\n",
        "        self.batch_size = kwargs.get(\"batch_size\", 64)\n",
        "        self.epochs = kwargs.get(\"epochs\", 1000)\n",
        "        \n",
        "        self.model_name = \"\"\n",
        "        self._update_model_name()\n",
        "\n",
        "        self.model = None\n",
        "\n",
        "        self._compute_input_length()\n",
        "\n",
        "        self.model_created = False\n",
        "\n",
        "    def _update_model_name(self):\n",
        "        emotions_str = get_first_letters(self.emotions)\n",
        "        problem_type = 'c' if self.classification else 'r'\n",
        "        dropout_str = get_dropout_str(self.dropout, n_layers=self.n_dense_layers + self.n_rnn_layers)\n",
        "        self.model_name = f\"{emotions_str}-{problem_type}-{self.cell.__name__}-layers-{self.n_rnn_layers}-{self.n_dense_layers}-units-{self.rnn_units}-{self.dense_units}-dropout-{dropout_str}.h5\"\n",
        "\n",
        "    def _get_model_filename(self):\n",
        "        \"\"\"Returns the relative path of this model name\"\"\"\n",
        "        return f\"results/{self.model_name}\"\n",
        "\n",
        "    def _model_exists(self):\n",
        "        \"\"\"\n",
        "        Checks if model already exists in disk, returns the filename,\n",
        "        and returns `None` otherwise.\n",
        "        \"\"\"\n",
        "        filename = self._get_model_filename()\n",
        "        return filename if os.path.isfile(filename) else None\n",
        "\n",
        "    def _compute_input_length(self):\n",
        "        \"\"\"\n",
        "        Calculates the input shape to be able to construct the model.\n",
        "        \"\"\"\n",
        "        if not self.data_loaded:\n",
        "            self.load_data()\n",
        "        self.input_length = self.X_train[0].shape[1]\n",
        "\n",
        "    def _verify_emotions(self):\n",
        "        super()._verify_emotions()\n",
        "        self.int2emotions = {i: e for i, e in enumerate(self.emotions)}\n",
        "        self.emotions2int = {v: k for k, v in self.int2emotions.items()}\n",
        "\n",
        "    def create_model(self):\n",
        "        \"\"\"\n",
        "        Constructs the neural network based on parameters passed.\n",
        "        \"\"\"\n",
        "        if self.model_created:\n",
        "            # model already created, why call twice\n",
        "            return\n",
        "\n",
        "        if not self.data_loaded:\n",
        "            # if data isn't loaded yet, load it\n",
        "            self.load_data()\n",
        "        \n",
        "        model = Sequential()\n",
        "\n",
        "        # rnn layers\n",
        "        for i in range(self.n_rnn_layers):\n",
        "            if i == 0:\n",
        "                # first layer\n",
        "                model.add(self.cell(self.rnn_units, return_sequences=True, input_shape=(None, self.input_length)))\n",
        "                model.add(Dropout(self.dropout[i]))\n",
        "            else:\n",
        "                # middle layers\n",
        "                model.add(self.cell(self.rnn_units, return_sequences=True))\n",
        "                model.add(Dropout(self.dropout[i]))\n",
        "\n",
        "        if self.n_rnn_layers == 0:\n",
        "            i = 0\n",
        "\n",
        "        # dense layers\n",
        "        for j in range(self.n_dense_layers):\n",
        "            # if n_rnn_layers = 0, only dense\n",
        "            if self.n_rnn_layers == 0 and j == 0:\n",
        "                model.add(Dense(self.dense_units, input_shape=(None, self.input_length)))\n",
        "                model.add(Dropout(self.dropout[i+j]))\n",
        "            else:\n",
        "                model.add(Dense(self.dense_units))\n",
        "                model.add(Dropout(self.dropout[i+j]))\n",
        "                \n",
        "        if self.classification:\n",
        "            model.add(Dense(self.output_dim, activation=\"softmax\"))\n",
        "            model.compile(loss=self.loss, metrics=[\"accuracy\"], optimizer=self.optimizer)\n",
        "        else:\n",
        "            model.add(Dense(1, activation=\"linear\"))\n",
        "            model.compile(loss=\"mean_squared_error\", metrics=[\"mean_absolute_error\"], optimizer=self.optimizer)\n",
        "        \n",
        "        self.model = model\n",
        "        self.model_created = True\n",
        "        if self.verbose > 0:\n",
        "            print(\"[+] Model created\")\n",
        "\n",
        "    def load_data(self):\n",
        "        \"\"\"\n",
        "        Loads and extracts features from the audio files for the db's specified.\n",
        "        And then reshapes the data.\n",
        "        \"\"\"\n",
        "        super().load_data()\n",
        "        # reshape X's to 3 dims\n",
        "        X_train_shape = self.X_train.shape\n",
        "        X_test_shape = self.X_test.shape\n",
        "        self.X_train = self.X_train.reshape((1, X_train_shape[0], X_train_shape[1]))\n",
        "        self.X_test = self.X_test.reshape((1, X_test_shape[0], X_test_shape[1]))\n",
        "\n",
        "        if self.classification:\n",
        "            # one-hot encode when its classification\n",
        "            self.y_train = to_categorical([ self.emotions2int[str(e)] for e in self.y_train ])\n",
        "            self.y_test = to_categorical([ self.emotions2int[str(e)] for e in self.y_test ])\n",
        "        \n",
        "        # reshape labels\n",
        "        y_train_shape = self.y_train.shape\n",
        "        y_test_shape = self.y_test.shape\n",
        "        if self.classification:\n",
        "            self.y_train = self.y_train.reshape((1, y_train_shape[0], y_train_shape[1]))    \n",
        "            self.y_test = self.y_test.reshape((1, y_test_shape[0], y_test_shape[1]))\n",
        "        else:\n",
        "            self.y_train = self.y_train.reshape((1, y_train_shape[0], 1))\n",
        "            self.y_test = self.y_test.reshape((1, y_test_shape[0], 1))\n",
        "\n",
        "    def train(self, override=False):\n",
        "        if not self.model_created:\n",
        "            self.create_model()\n",
        "\n",
        "        if not override:\n",
        "            model_name = self._model_exists()\n",
        "            if model_name:\n",
        "                self.model.load_weights(model_name)\n",
        "                self.model_trained = True\n",
        "                if self.verbose > 0:\n",
        "                    print(\"[*] Model weights loaded\")\n",
        "                return\n",
        "        \n",
        "        if not os.path.isdir(\"results\"):\n",
        "            os.mkdir(\"results\")\n",
        "\n",
        "        if not os.path.isdir(\"logs\"):\n",
        "            os.mkdir(\"logs\")\n",
        "\n",
        "        model_filename = self._get_model_filename()\n",
        "\n",
        "        self.checkpointer = ModelCheckpoint(model_filename, save_best_only=True, verbose=1)\n",
        "        self.tensorboard = TensorBoard(log_dir=f\"logs/{self.model_name}\")\n",
        "\n",
        "        self.history = self.model.fit(self.X_train, self.y_train,\n",
        "                        batch_size=self.batch_size,\n",
        "                        epochs=self.epochs,\n",
        "                        validation_data=(self.X_test, self.y_test),\n",
        "                        callbacks=[self.checkpointer, self.tensorboard],\n",
        "                        verbose=self.verbose)\n",
        "        \n",
        "        self.model_trained = True\n",
        "        if self.verbose > 0:\n",
        "            print(\"[+] Model trained\")\n",
        "\n",
        "    def predict(self, audio_path):\n",
        "        feature = extract_feature(audio_path, **self.audio_config).reshape((1, 1, self.input_length))\n",
        "        if self.classification:\n",
        "            return self.int2emotions[self.model.predict_classes(feature)[0][0]]\n",
        "        else:\n",
        "            return self.model.predict(feature)[0][0][0]\n",
        "\n",
        "    def predict_proba(self, audio_path):\n",
        "        if self.classification:\n",
        "            feature = extract_feature(audio_path, **self.audio_config).reshape((1, 1, self.input_length))\n",
        "            proba = self.model.predict(feature)[0][0]\n",
        "            result = {}\n",
        "            for prob, emotion in zip(proba, self.emotions):\n",
        "                result[emotion] = prob\n",
        "            return result\n",
        "        else:\n",
        "            raise NotImplementedError(\"Probability prediction doesn't make sense for regression\")\n",
        "\n",
        "\n",
        "\n",
        "    def test_score(self):\n",
        "        y_test = self.y_test[0]\n",
        "        if self.classification:\n",
        "            y_pred = self.model.predict_classes(self.X_test)[0]\n",
        "            y_test = [np.argmax(y, out=None, axis=None) for y in y_test]\n",
        "            return accuracy_score(y_true=y_test, y_pred=y_pred)\n",
        "        else:\n",
        "            y_pred = self.model.predict(self.X_test)[0]\n",
        "            return mean_absolute_error(y_true=y_test, y_pred=y_pred)\n",
        "\n",
        "    def train_score(self):\n",
        "        y_train = self.y_train[0]\n",
        "        if self.classification:\n",
        "            y_pred = self.model.predict_classes(self.X_train)[0]\n",
        "            y_train = [np.argmax(y, out=None, axis=None) for y in y_train]\n",
        "            return accuracy_score(y_true=y_train, y_pred=y_pred)\n",
        "        else:\n",
        "            y_pred = self.model.predict(self.X_train)[0]\n",
        "            return mean_absolute_error(y_true=y_train, y_pred=y_pred)\n",
        "\n",
        "    def confusion_matrix(self, percentage=True, labeled=True):\n",
        "        \"\"\"Compute confusion matrix to evaluate the test accuracy of the classification\"\"\"\n",
        "        if not self.classification:\n",
        "            raise NotImplementedError(\"Confusion matrix works only when it is a classification problem\")\n",
        "        y_pred = self.model.predict_classes(self.X_test)[0]\n",
        "        # invert from keras.utils.to_categorical\n",
        "        y_test = np.array([ np.argmax(y, axis=None, out=None) for y in self.y_test[0] ])\n",
        "        print(classification_report(y_test,y_pred))\n",
        "        matrix = confusion_matrix(y_test, y_pred, labels=[self.emotions2int[e] for e in self.emotions]).astype(np.float32)\n",
        "        index = ['angry',  'happy', 'neutral', 'sad', 'surprised']  \n",
        "        columns = ['angry',  'happy', 'neutral', 'sad', 'surprised']  \n",
        "        cm_df = pd.DataFrame(matrix, index, columns)                      \n",
        "        plt.figure(figsize=(10,6))  \n",
        "        sns.heatmap(cm_df, annot=True)\n",
        "        if percentage:\n",
        "            for i in range(len(matrix)):\n",
        "                matrix[i] = matrix[i] / np.sum(matrix[i])\n",
        "            # make it percentage\n",
        "            matrix *= 100\n",
        "        if labeled:\n",
        "            matrix = pd.DataFrame(matrix, index=[ f\"true_{e}\" for e in self.emotions ],\n",
        "                                    columns=[ f\"predicted_{e}\" for e in self.emotions ])\n",
        "        return matrix\n",
        "\n",
        "    def n_emotions(self, emotion, partition):\n",
        "        \"\"\"Returns number of `emotion` data samples in a particular `partition`\n",
        "        ('test' or 'train')\n",
        "        \"\"\"\n",
        "        if partition == \"test\":\n",
        "            if self.classification:\n",
        "                y_test = np.array([ np.argmax(y, axis=None, out=None)+1 for y in np.squeeze(self.y_test) ]) \n",
        "            else:\n",
        "                y_test = np.squeeze(self.y_test)\n",
        "            return len([y for y in y_test if y == emotion])\n",
        "        elif partition == \"train\":\n",
        "            if self.classification:\n",
        "                y_train = np.array([ np.argmax(y, axis=None, out=None)+1 for y in np.squeeze(self.y_train) ])\n",
        "            else:\n",
        "                y_train = np.squeeze(self.y_train)\n",
        "            return len([y for y in y_train if y == emotion])\n",
        "\n",
        "    def get_samples_by_class(self):\n",
        "        \"\"\"\n",
        "        Returns a dataframe that contains the number of training \n",
        "        and testing samples for all emotions\n",
        "        \"\"\"\n",
        "        train_samples = []\n",
        "        test_samples = []\n",
        "        total = []\n",
        "        for emotion in self.emotions:\n",
        "            n_train = self.n_emotions(self.emotions2int[emotion]+1, \"train\")\n",
        "            n_test = self.n_emotions(self.emotions2int[emotion]+1, \"test\")\n",
        "            train_samples.append(n_train)\n",
        "            test_samples.append(n_test)\n",
        "            total.append(n_train + n_test)\n",
        "        \n",
        "        # get total\n",
        "        total.append(sum(train_samples) + sum(test_samples))\n",
        "        train_samples.append(sum(train_samples))\n",
        "        test_samples.append(sum(test_samples))\n",
        "        return pd.DataFrame(data={\"train\": train_samples, \"test\": test_samples, \"total\": total}, index=self.emotions + [\"total\"])\n",
        "\n",
        "    def get_random_emotion(self, emotion, partition=\"train\"):\n",
        "        \"\"\"\n",
        "        Returns random `emotion` data sample index on `partition`\n",
        "        \"\"\"\n",
        "        if partition == \"train\":\n",
        "            y_train = self.y_train[0]\n",
        "            index = random.choice(list(range(len(y_train))))\n",
        "            element = self.int2emotions[np.argmax(y_train[index])]\n",
        "            while element != emotion:\n",
        "                index = random.choice(list(range(len(y_train))))\n",
        "                element = self.int2emotions[np.argmax(y_train[index])]\n",
        "        elif partition == \"test\":\n",
        "            y_test = self.y_test[0]\n",
        "            index = random.choice(list(range(len(y_test))))\n",
        "            element = self.int2emotions[np.argmax(y_test[index])]\n",
        "            while element != emotion:\n",
        "                index = random.choice(list(range(len(y_test))))\n",
        "                element = self.int2emotions[np.argmax(y_test[index])]\n",
        "        else:\n",
        "            raise TypeError(\"Unknown partition, only 'train' or 'test' is accepted\")\n",
        "\n",
        "        return index\n",
        "\n",
        "    def determine_best_model(self, train=True):\n",
        "        # TODO\n",
        "        raise TypeError(\"This method isn't supported yet for deep nn\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNGGrHBZ5xiw"
      },
      "source": [
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyLlLvABuCGK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "58072db7-c6df-4379-db76-517e9f605d2b"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "    rec = DeepEmotionRecognizer(emotions=['angry', 'sad', 'neutral', 'ps', 'happy'],\n",
        "                                epochs=300, verbose=0)\n",
        "    rec.train(override=False)\n",
        "    print(\"Test accuracy score:\", rec.test_score() * 100, \"%\")\n",
        "    print(rec.confusion_matrix())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy score: 90.25641025641026 %\n",
            "              predicted_angry  predicted_sad  ...  predicted_ps  predicted_happy\n",
            "true_angry          93.589745       1.282051  ...      3.846154         1.282051\n",
            "true_sad             0.000000      93.589745  ...      5.128205         0.000000\n",
            "true_neutral         1.282051       7.692308  ...      0.000000         0.000000\n",
            "true_ps              5.128205       0.000000  ...     84.615387        10.256411\n",
            "true_happy           7.692308       0.000000  ...      3.846154        88.461533\n",
            "\n",
            "[5 rows x 5 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwC6hchf3z2I"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}